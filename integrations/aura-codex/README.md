<p align="center">
  <img src="https://raw.githubusercontent.com/Auralith-Inc/aura-core/main/logo.png" alt="Aura" width="100">
</p>

# ðŸ”¥ Aura for OpenAI Codex

**Give your Codex agent a persistent knowledge base and 3-tier memory compiled from any documents.**

<p align="center">
  <a href="https://pypi.org/project/auralith-aura/"><img src="https://badge.fury.io/py/auralith-aura.svg" alt="PyPI"></a>
  <a href="https://github.com/Auralith-Inc/aura-core#-license"><img src="https://img.shields.io/badge/License-Apache_2.0_+_Proprietary-blue.svg" alt="License"></a>
</p>

## What This Does

This skill gives your Codex agent the ability to:

1. **Compile** any folder of documents (PDFs, DOCX, code, spreadsheets, markdown â€” 60+ formats) into a `.aura` knowledge base
2. **Query** that knowledge base instantly with natural language
3. **Remember** facts and context across sessions with the 3-tier Memory OS (pad, episodic, fact)

> **Memory OS v2.1** (`auralith-aura>=0.2.2`): Enhanced with temporal decay scoring, noise filtering, deduplication, bloom filters, SimHash fuzzy matching, and tiered priority scoring â€” zero RAM overhead.

All processing happens **locally on your machine**. No data leaves your device.

## Setup

### 1. Install Aura Core

```bash
pip install auralith-aura
```

### 2. Add the Skill

Copy the `SKILL.md` and `scripts/` directory into your Codex skills folder:

```bash
# User-wide (available in all projects)
mkdir -p ~/.codex/skills/aura
cp SKILL.md scripts/ ~/.codex/skills/aura/

# Or project-specific (shared via version control)
mkdir -p .codex/skills/aura
cp SKILL.md scripts/ .codex/skills/aura/
```

## Usage

### Compile a Knowledge Base

```
You: Compile all documentation in ./docs into a knowledge base
Codex: Running: aura compile ./docs --output knowledge.aura
       âœ… Knowledge base compiled â€” documents indexed
```

### Query Documents

```
You: Search the knowledge base for how the payment system works
Codex: Found relevant documents:
       ðŸ“„ payment_flow.md
       ðŸ“„ stripe_integration.py
       ðŸ“„ api_reference.md
```

### Use Agent Memory

```
You: Remember that our production database is on us-east-1
Codex: âœ… Written to fact tier

--- next session ---

You: Where is our production database?
Codex: Based on stored memory: Your production database is on us-east-1
```

## How It Works

```python
# The skill uses Aura's Python API
from aura.rag import AuraRAGLoader

loader = AuraRAGLoader("knowledge.aura")

# Get text from any document
text = loader.get_text_by_id("payment_flow")

# Search across all documents
for doc_id, text, meta in loader.iterate_texts():
    if "payment" in text.lower():
        print(f"Found: {meta['source']}")

# Framework wrappers
langchain_docs = loader.to_langchain_documents()
llama_docs = loader.to_llama_index_documents()
```

## Runs Locally

- **Runs on your local hardware** â€” any modern laptop or desktop, your setup, your choice
- **Fully offline** â€” zero internet required after install
- **Cross-platform** â€” macOS, Windows, Linux, Python 3.8+

Your documents never leave your hardware.

## Scale Up with OMNI

Need enterprise-scale training pipelines, model fine-tuning, or production agent infrastructure? Check out [**OMNI**](https://omni.auralith.org).

## Links

- [Aura Core](https://github.com/Auralith-Inc/aura-core) â€” The compiler
- [Website](https://aura.auralith.org) â€” Documentation
- [OMNI Platform](https://omni.auralith.org) â€” Enterprise scale
- [PyPI](https://pypi.org/project/auralith-aura/) â€” Install

---

Made by [Auralith Inc.](https://auralith.org)
